/**
 * å°ç¨‹åºä¸“ç”¨éŸ³é¢‘å®¢æˆ·ç«¯
 * ä½¿ç”¨ WebSocket è¿æ¥ Edge Function ä¸­ç»§æœåŠ¡å™¨ï¼Œå®ç°ä¸ OpenAI Realtime API çš„é€šä¿¡
 * 
 * æ¶æ„ï¼š
 * å°ç¨‹åº wx.å½•éŸ³API <-> WebSocket <-> Edge Function <-> OpenAI Realtime API
 */

import { supabase } from '@/integrations/supabase/client';

// æ‰©å±• Window æ¥å£ä»¥æ”¯æŒå°ç¨‹åº APIï¼ˆä¸ platform.ts ä¿æŒä¸€è‡´ï¼‰
declare global {
  interface Window {
    wx?: {
      miniProgram?: {
        getEnv: (callback: (res: { miniprogram: boolean }) => void) => void;
      };
      getRecorderManager?: () => any;
      createInnerAudioContext?: () => {
        src: string;
        obeyMuteSwitch: boolean;
        play: () => void;
        stop: () => void;
        onEnded: (callback: () => void) => void;
        offEnded: () => void;
        onError: (callback: (error: any) => void) => void;
      };
      authorize?: (options: any) => void;
      canIUse?: (api: string) => boolean;
      arrayBufferToBase64?: (buffer: ArrayBuffer) => string;
      base64ToArrayBuffer?: (base64: string) => ArrayBuffer;
      getFileSystemManager?: () => {
        writeFile: (options: {
          filePath: string;
          data: ArrayBuffer | string;
          encoding?: string;
          success?: () => void;
          fail?: (err: { errMsg?: string }) => void;
        }) => void;
        readFile: (options: any) => void;
        unlink: (options: {
          filePath: string;
          success?: () => void;
          fail?: (err: { errMsg?: string }) => void;
        }) => void;
      };
      env?: {
        USER_DATA_PATH: string;
      };
    };
  }
}

export type ConnectionStatus = 'disconnected' | 'connecting' | 'connected' | 'error';

export interface MiniProgramAudioConfig {
  onMessage: (message: any) => void;
  onStatusChange: (status: ConnectionStatus) => void;
  onTranscript: (text: string, isFinal: boolean, role: 'user' | 'assistant') => void;
  onUsageUpdate?: (usage: { input_tokens: number; output_tokens: number }) => void;
  tokenEndpoint: string;
  mode: string;
}

interface AudioChunk {
  type: 'audio_input';
  audio: string; // Base64 encoded PCM16 audio
}

interface ServerMessage {
  type: string;
  text?: string;
  audio?: string;
  isFinal?: boolean;
  role?: 'user' | 'assistant';
  usage?: {
    input_tokens: number;
    output_tokens: number;
  };
  error?: string;
}

export class MiniProgramAudioClient {
  private ws: WebSocket | null = null;
  private recorder: any = null;
  private audioPlayer: any = null;
  private audioQueue: string[] = [];
  private isPlaying = false;
  private status: ConnectionStatus = 'disconnected';
  private reconnectAttempts = 0;
  private maxReconnectAttempts = 3;
  private heartbeatInterval: ReturnType<typeof setInterval> | null = null;
  private config: MiniProgramAudioConfig;
  
  // ğŸ”§ Web Audio API é™çº§å½•éŸ³ç›¸å…³
  private webAudioContext: AudioContext | null = null;
  private webMediaStream: MediaStream | null = null;
  private webProcessor: ScriptProcessorNode | null = null;
  private webSource: MediaStreamAudioSourceNode | null = null;
  private useWebAudioFallback = false;

  constructor(config: MiniProgramAudioConfig) {
    this.config = config;
  }

  /**
   * è¿æ¥åˆ° WebSocket ä¸­ç»§æœåŠ¡å™¨
   */
  async connect(): Promise<void> {
    try {
      this.updateStatus('connecting');

      // 1. è·å– ephemeral token
      const token = await this.getEphemeralToken();
      if (!token) {
        throw new Error('Failed to get ephemeral token');
      }

      // 2. æ„å»º WebSocket URL
      const wsUrl = this.buildWebSocketUrl(token);

      // 3. å»ºç«‹ WebSocket è¿æ¥
      await this.establishWebSocket(wsUrl);

      // 4. åˆå§‹åŒ–å½•éŸ³å™¨
      await this.initRecorder();

      // 5. åˆå§‹åŒ–æ’­æ”¾å™¨
      this.initAudioPlayer();

      // 6. å¯åŠ¨å¿ƒè·³
      this.startHeartbeat();

      this.updateStatus('connected');
      this.reconnectAttempts = 0;
    } catch (error) {
      console.error('[MiniProgramAudio] Connection failed:', error);
      this.updateStatus('error');
      throw error;
    }
  }

  /**
   * æ–­å¼€è¿æ¥
   */
  disconnect(): void {
    this.stopHeartbeat();
    this.stopRecording();
    this.stopAudioPlayback();

    if (this.ws) {
      this.ws.close();
      this.ws = null;
    }

    this.updateStatus('disconnected');
  }

  /**
   * å¼€å§‹å½•éŸ³
   */
  startRecording(): void {
    if (this.useWebAudioFallback) {
      // Web Audio API æ¨¡å¼ï¼šå½•éŸ³å·²åœ¨åˆå§‹åŒ–æ—¶è‡ªåŠ¨å¼€å§‹
      console.log('[MiniProgramAudio] Web Audio recording already started');
      return;
    }
    
    if (!this.recorder) {
      console.error('[MiniProgramAudio] Recorder not initialized');
      return;
    }

    const wx = window.wx;
    if (!wx) return;

    this.recorder.start({
      duration: 60000, // æœ€é•¿ 60 ç§’
      sampleRate: 24000, // 24kHz é‡‡æ ·ç‡ï¼ˆOpenAI è¦æ±‚ï¼‰
      numberOfChannels: 1, // å•å£°é“
      encodeBitRate: 96000, // æé«˜ç ç‡ï¼Œæ”¹å–„éŸ³è´¨
      format: 'PCM', // PCM æ ¼å¼
      frameSize: 6, // æ¯å¸§ 6KBï¼Œå‡å°‘åˆ†ç‰‡å’Œç½‘ç»œå¼€é”€
    });
  }

  /**
   * åœæ­¢å½•éŸ³
   */
  stopRecording(): void {
    // åœæ­¢ Web Audio API å½•éŸ³
    if (this.useWebAudioFallback) {
      this.stopWebAudioRecording();
      return;
    }
    
    if (this.recorder) {
      try {
        this.recorder.stop();
      } catch (e) {
        // Ignore stop errors
      }
    }
  }

  /**
   * å‘é€æ–‡æœ¬æ¶ˆæ¯
   */
  sendTextMessage(text: string): void {
    if (!this.ws || this.ws.readyState !== WebSocket.OPEN) {
      console.error('[MiniProgramAudio] WebSocket not connected');
      return;
    }

    this.ws.send(JSON.stringify({
      type: 'text_input',
      text,
    }));
  }

  /**
   * è·å–å½“å‰çŠ¶æ€
   */
  getStatus(): ConnectionStatus {
    return this.status;
  }

  // ==================== Private Methods ====================

  private async getEphemeralToken(): Promise<string | null> {
    try {
      const { data, error } = await supabase.functions.invoke(this.config.tokenEndpoint, {
        body: { mode: this.config.mode },
      });

      if (error) {
        console.error('[MiniProgramAudio] Token error:', error);
        return null;
      }

      return data?.client_secret?.value || null;
    } catch (error) {
      console.error('[MiniProgramAudio] Token fetch failed:', error);
      return null;
    }
  }

  private buildWebSocketUrl(token: string): string {
    // ä½¿ç”¨ Supabase Edge Function çš„ WebSocket ç«¯ç‚¹
    const projectId = import.meta.env.VITE_SUPABASE_PROJECT_ID;
    const baseUrl = `wss://${projectId}.supabase.co/functions/v1/miniprogram-voice-relay`;
    
    // å°† token å’Œ mode ä½œä¸ºæŸ¥è¯¢å‚æ•°
    const params = new URLSearchParams({
      token,
      mode: this.config.mode,
    });

    return `${baseUrl}?${params.toString()}`;
  }

  private establishWebSocket(url: string): Promise<void> {
    return new Promise((resolve, reject) => {
      this.ws = new WebSocket(url);

      const timeout = setTimeout(() => {
        reject(new Error('WebSocket connection timeout'));
      }, 10000);

      this.ws.onopen = () => {
        clearTimeout(timeout);
        console.log('[MiniProgramAudio] WebSocket connected');
        resolve();
      };

      this.ws.onmessage = (event) => {
        this.handleServerMessage(event.data);
      };

      this.ws.onerror = (error) => {
        clearTimeout(timeout);
        console.error('[MiniProgramAudio] WebSocket error:', error);
        reject(error);
      };

      this.ws.onclose = (event) => {
        console.log('[MiniProgramAudio] WebSocket closed:', event.code, event.reason);
        this.handleDisconnect();
      };
    });
  }

  private async initRecorder(): Promise<void> {
    const wx = window.wx;
    
    // ğŸ”§ ä¼˜å…ˆä½¿ç”¨å°ç¨‹åºåŸç”Ÿ API
    if (wx?.getRecorderManager) {
      console.log('[MiniProgramAudio] Using wx.getRecorderManager');
      
      // è¯·æ±‚å½•éŸ³æƒé™
      const hasPermission = await this.requestRecordPermission();
      if (!hasPermission) {
        throw new Error('Recording permission denied');
      }

      this.recorder = wx.getRecorderManager();

      // ç›‘å¬å½•éŸ³å¸§æ•°æ®
      this.recorder.onFrameRecorded((res: { frameBuffer: ArrayBuffer; isLastFrame: boolean }) => {
        if (this.ws?.readyState === WebSocket.OPEN && res.frameBuffer) {
          // å°†éŸ³é¢‘æ•°æ®è½¬ä¸º Base64 å¹¶å‘é€
          const base64Audio = wx.arrayBufferToBase64?.(res.frameBuffer) || '';
          if (base64Audio) {
            const chunk: AudioChunk = {
              type: 'audio_input',
              audio: base64Audio,
            };
            this.ws.send(JSON.stringify(chunk));
          }
        }
      });

      // ç›‘å¬å½•éŸ³é”™è¯¯
      this.recorder.onError((error: any) => {
        console.error('[MiniProgramAudio] Recorder error:', error);
      });

      // ç›‘å¬å½•éŸ³ç»“æŸ
      this.recorder.onStop(() => {
        console.log('[MiniProgramAudio] Recording stopped');
      });
      
      return;
    }

    // ğŸ”§ é™çº§ä¸º Web Audio APIï¼ˆå°ç¨‹åº WebView ä¸­ä½¿ç”¨ï¼‰
    console.log('[MiniProgramAudio] wx.getRecorderManager not available, using Web Audio API fallback');
    this.useWebAudioFallback = true;
    
    try {
      // è¯·æ±‚éº¦å…‹é£æƒé™
      this.webMediaStream = await navigator.mediaDevices.getUserMedia({
        audio: {
          sampleRate: 24000,
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        }
      });
      
      // åˆ›å»º AudioContext
      this.webAudioContext = new (window.AudioContext || (window as any).webkitAudioContext)({
        sampleRate: 24000
      });
      
      // åˆ›å»ºéŸ³é¢‘æº
      this.webSource = this.webAudioContext.createMediaStreamSource(this.webMediaStream);
      
      // åˆ›å»ºå¤„ç†èŠ‚ç‚¹ï¼ˆæ¯å¸§ 8192 æ ·æœ¬ï¼Œå‡å°‘æ•°æ®ç¢ç‰‡æå‡éŸ³è´¨ï¼‰
      this.webProcessor = this.webAudioContext.createScriptProcessor(8192, 1, 1);
      
      this.webProcessor.onaudioprocess = (e) => {
        if (this.ws?.readyState !== WebSocket.OPEN) return;
        
        const inputData = e.inputBuffer.getChannelData(0);
        
        // è½¬æ¢ä¸º PCM16 æ ¼å¼
        const int16Array = new Int16Array(inputData.length);
        for (let i = 0; i < inputData.length; i++) {
          const s = Math.max(-1, Math.min(1, inputData[i]));
          int16Array[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
        }
        
        // è½¬æ¢ä¸º Base64
        const uint8Array = new Uint8Array(int16Array.buffer);
        let binary = '';
        const chunkSize = 0x8000;
        for (let i = 0; i < uint8Array.length; i += chunkSize) {
          const chunk = uint8Array.subarray(i, Math.min(i + chunkSize, uint8Array.length));
          binary += String.fromCharCode.apply(null, Array.from(chunk));
        }
        const base64Audio = btoa(binary);
        
        // å‘é€åˆ°æœåŠ¡å™¨
        const audioChunk: AudioChunk = {
          type: 'audio_input',
          audio: base64Audio,
        };
        this.ws?.send(JSON.stringify(audioChunk));
      };
      
      // è¿æ¥èŠ‚ç‚¹ï¼ˆé™éŸ³è¾“å‡ºï¼Œé¿å…å›å£°ï¼‰
      this.webSource.connect(this.webProcessor);
      const silentGain = this.webAudioContext.createGain();
      silentGain.gain.value = 0;
      this.webProcessor.connect(silentGain);
      silentGain.connect(this.webAudioContext.destination);
      
      console.log('[MiniProgramAudio] Web Audio API recorder initialized');
    } catch (error) {
      console.error('[MiniProgramAudio] Web Audio API init failed:', error);
      throw new Error('éº¦å…‹é£æƒé™ä¸è¶³ï¼Œè¯·å…è®¸è®¿é—®éº¦å…‹é£');
    }
  }

  /**
   * åœæ­¢ Web Audio API å½•éŸ³
   */
  private stopWebAudioRecording(): void {
    if (this.webSource) {
      this.webSource.disconnect();
      this.webSource = null;
    }
    if (this.webProcessor) {
      this.webProcessor.disconnect();
      this.webProcessor = null;
    }
    if (this.webMediaStream) {
      this.webMediaStream.getTracks().forEach(track => track.stop());
      this.webMediaStream = null;
    }
    if (this.webAudioContext) {
      this.webAudioContext.close();
      this.webAudioContext = null;
    }
    console.log('[MiniProgramAudio] Web Audio recording stopped');
  }

  private requestRecordPermission(): Promise<boolean> {
    const wx = window.wx;
    if (!wx?.authorize) {
      return Promise.resolve(true); // éå°ç¨‹åºç¯å¢ƒï¼Œå‡è®¾æœ‰æƒé™
    }

    return new Promise((resolve) => {
      wx.authorize({
        scope: 'scope.record',
        success: () => resolve(true),
        fail: () => resolve(false),
      });
    });
  }

  private initAudioPlayer(): void {
    const wx = window.wx;
    if (!wx?.createInnerAudioContext) {
      console.warn('[MiniProgramAudio] wx.createInnerAudioContext not available');
      // Web ç¯å¢ƒä¸éœ€è¦ audioPlayerï¼Œä½¿ç”¨ Web Audio API
      return;
    }

    this.audioPlayer = wx.createInnerAudioContext();
    this.audioPlayer.obeyMuteSwitch = false; // ä¸å—é™éŸ³å¼€å…³å½±å“

    // æ³¨æ„ï¼šonEnded åœ¨ playNextInQueue ä¸­åŠ¨æ€ç»‘å®šï¼Œè¿™é‡Œåªç»‘å®šé”™è¯¯å¤„ç†
    this.audioPlayer.onError((error: any) => {
      console.error('[MiniProgramAudio] Audio player error:', error);
      this.isPlaying = false;
      this.playNextInQueue();
    });
  }

  private handleServerMessage(data: string): void {
    try {
      const message: ServerMessage = JSON.parse(data);

      switch (message.type) {
        case 'transcript':
          // å¤„ç†è½¬å½•æ–‡æœ¬
          if (message.text) {
            this.config.onTranscript(
              message.text,
              message.isFinal ?? true,
              message.role ?? 'assistant'
            );
          }
          break;

        case 'audio_output':
          // å¤„ç†éŸ³é¢‘è¾“å‡º
          if (message.audio) {
            this.queueAudio(message.audio);
          }
          break;

        case 'usage':
          // å¤„ç† token ä½¿ç”¨é‡
          if (message.usage && this.config.onUsageUpdate) {
            this.config.onUsageUpdate(message.usage);
          }
          break;

        case 'error':
          console.error('[MiniProgramAudio] Server error:', message.error);
          this.updateStatus('error');
          break;

        case 'pong':
          // å¿ƒè·³å“åº”
          break;

        default:
          // å…¶ä»–æ¶ˆæ¯ä¼ é€’ç»™å›è°ƒ
          this.config.onMessage(message);
      }
    } catch (error) {
      console.error('[MiniProgramAudio] Failed to parse message:', error);
    }
  }

  private queueAudio(base64Audio: string): void {
    this.audioQueue.push(base64Audio);
    if (!this.isPlaying) {
      this.playNextInQueue();
    }
  }

  private playNextInQueue(): void {
    if (this.audioQueue.length === 0) {
      this.isPlaying = false;
      return;
    }

    const base64Audio = this.audioQueue.shift();
    if (!base64Audio) {
      this.isPlaying = false;
      return;
    }

    this.isPlaying = true;

    try {
      const wx = window.wx;
      
      if (wx?.getFileSystemManager && wx?.env?.USER_DATA_PATH && this.audioPlayer) {
        // å°ç¨‹åºç¯å¢ƒï¼šå°† PCM è½¬æ¢ä¸º WAV æ ¼å¼åæ’­æ”¾
        const fs = wx.getFileSystemManager();
        const pcmBuffer = wx.base64ToArrayBuffer?.(base64Audio);
        
        if (!pcmBuffer) {
          console.error('[MiniProgramAudio] Failed to convert base64 to ArrayBuffer');
          this.isPlaying = false;
          this.playNextInQueue();
          return;
        }
        
        // PCM è½¬ WAVï¼šæ·»åŠ  44 å­—èŠ‚çš„ WAV å¤´
        const wavBuffer = this.pcmToWav(pcmBuffer, 24000, 1, 16);
        const tempPath = `${wx.env.USER_DATA_PATH}/audio_${Date.now()}.wav`;
        
        // å…ˆæ¸…ç†ä¹‹å‰çš„äº‹ä»¶ç›‘å¬å™¨ï¼Œé¿å…é‡å¤ç»‘å®š
        this.audioPlayer.offEnded();
        
        fs.writeFile({
          filePath: tempPath,
          data: wavBuffer,
          encoding: 'binary',
          success: () => {
            if (this.audioPlayer) {
              // ç»‘å®šæ’­æ”¾ç»“æŸäº‹ä»¶
              this.audioPlayer.onEnded(() => {
                // åˆ é™¤ä¸´æ—¶æ–‡ä»¶
                fs.unlink({
                  filePath: tempPath,
                  success: () => {},
                  fail: () => {}
                });
                // ç»§ç»­æ’­æ”¾é˜Ÿåˆ—
                this.isPlaying = false;
                this.playNextInQueue();
              });
              
              this.audioPlayer.src = tempPath;
              this.audioPlayer.play();
            }
          },
          fail: (err: { errMsg?: string }) => {
            console.error('[MiniProgramAudio] Failed to write audio file:', err);
            this.isPlaying = false;
            this.playNextInQueue();
          }
        });
      } else {
        // Web ç¯å¢ƒé™çº§ï¼šä½¿ç”¨ Web Audio API æ’­æ”¾ PCM
        this.playPCMWithWebAudio(base64Audio);
      }
    } catch (error) {
      console.error('[MiniProgramAudio] Error playing audio:', error);
      this.isPlaying = false;
      this.playNextInQueue();
    }
  }

  /**
   * å°† PCM æ•°æ®è½¬æ¢ä¸º WAV æ ¼å¼
   * æ·»åŠ  44 å­—èŠ‚çš„ WAV æ–‡ä»¶å¤´
   */
  private pcmToWav(pcmData: ArrayBuffer, sampleRate: number, numChannels: number, bitsPerSample: number): ArrayBuffer {
    const dataLength = pcmData.byteLength;
    const buffer = new ArrayBuffer(44 + dataLength);
    const view = new DataView(buffer);

    // RIFF chunk descriptor
    this.writeString(view, 0, 'RIFF');
    view.setUint32(4, 36 + dataLength, true);
    this.writeString(view, 8, 'WAVE');

    // fmt sub-chunk
    this.writeString(view, 12, 'fmt ');
    view.setUint32(16, 16, true); // Subchunk1Size (16 for PCM)
    view.setUint16(20, 1, true); // AudioFormat (1 for PCM)
    view.setUint16(22, numChannels, true);
    view.setUint32(24, sampleRate, true);
    view.setUint32(28, sampleRate * numChannels * bitsPerSample / 8, true); // ByteRate
    view.setUint16(32, numChannels * bitsPerSample / 8, true); // BlockAlign
    view.setUint16(34, bitsPerSample, true);

    // data sub-chunk
    this.writeString(view, 36, 'data');
    view.setUint32(40, dataLength, true);

    // Write PCM data
    const pcmView = new Uint8Array(pcmData);
    const wavView = new Uint8Array(buffer);
    wavView.set(pcmView, 44);

    return buffer;
  }

  private writeString(view: DataView, offset: number, string: string): void {
    for (let i = 0; i < string.length; i++) {
      view.setUint8(offset + i, string.charCodeAt(i));
    }
  }

  /**
   * Web ç¯å¢ƒä¸‹ä½¿ç”¨ Web Audio API æ’­æ”¾ PCM
   */
  /**
   * Base64 è½¬ ArrayBufferï¼ˆå…¼å®¹ Web å’Œå°ç¨‹åºï¼‰
   */
  private base64ToArrayBuffer(base64: string): ArrayBuffer | null {
    try {
      // ä¼˜å…ˆä½¿ç”¨å°ç¨‹åº API
      if (window.wx?.base64ToArrayBuffer) {
        return window.wx.base64ToArrayBuffer(base64);
      }
      // Web ç¯å¢ƒé™çº§
      const binaryString = atob(base64);
      const bytes = new Uint8Array(binaryString.length);
      for (let i = 0; i < binaryString.length; i++) {
        bytes[i] = binaryString.charCodeAt(i);
      }
      return bytes.buffer;
    } catch (error) {
      console.error('[MiniProgramAudio] base64ToArrayBuffer error:', error);
      return null;
    }
  }

  private playPCMWithWebAudio(base64Audio: string): void {
    try {
      const arrayBuffer = this.base64ToArrayBuffer(base64Audio);
      
      if (!arrayBuffer) {
        this.isPlaying = false;
        this.playNextInQueue();
        return;
      }

      // ä½¿ç”¨ AudioContext æ’­æ”¾ PCM
      const audioContext = new (window.AudioContext || (window as any).webkitAudioContext)();
      const sampleRate = 24000;
      const numChannels = 1;
      
      // å°† PCM16 è½¬æ¢ä¸º Float32
      const pcmData = new Int16Array(arrayBuffer);
      const floatData = new Float32Array(pcmData.length);
      for (let i = 0; i < pcmData.length; i++) {
        floatData[i] = pcmData[i] / 32768.0;
      }

      const audioBuffer = audioContext.createBuffer(numChannels, floatData.length, sampleRate);
      audioBuffer.getChannelData(0).set(floatData);

      const source = audioContext.createBufferSource();
      source.buffer = audioBuffer;
      source.connect(audioContext.destination);
      source.onended = () => {
        this.isPlaying = false;
        this.playNextInQueue();
        audioContext.close();
      };
      source.start();
    } catch (error) {
      console.error('[MiniProgramAudio] Web Audio playback error:', error);
      this.isPlaying = false;
      this.playNextInQueue();
    }
  }

  private stopAudioPlayback(): void {
    this.audioQueue = [];
    this.isPlaying = false;
    if (this.audioPlayer) {
      try {
        this.audioPlayer.stop();
      } catch (e) {
        // Ignore stop errors
      }
    }
  }

  private startHeartbeat(): void {
    this.heartbeatInterval = setInterval(() => {
      if (this.ws?.readyState === WebSocket.OPEN) {
        this.ws.send(JSON.stringify({ type: 'ping' }));
      }
    }, 30000); // æ¯ 30 ç§’å‘é€å¿ƒè·³
  }

  private stopHeartbeat(): void {
    if (this.heartbeatInterval) {
      clearInterval(this.heartbeatInterval);
      this.heartbeatInterval = null;
    }
  }

  private handleDisconnect(): void {
    this.stopHeartbeat();
    
    if (this.status === 'connected' && this.reconnectAttempts < this.maxReconnectAttempts) {
      this.reconnectAttempts++;
      console.log(`[MiniProgramAudio] Attempting reconnect ${this.reconnectAttempts}/${this.maxReconnectAttempts}`);
      
      setTimeout(() => {
        this.connect().catch((error) => {
          console.error('[MiniProgramAudio] Reconnect failed:', error);
        });
      }, 1000 * this.reconnectAttempts); // æŒ‡æ•°é€€é¿
    } else {
      this.updateStatus('disconnected');
    }
  }

  private updateStatus(status: ConnectionStatus): void {
    this.status = status;
    this.config.onStatusChange(status);
  }
}
