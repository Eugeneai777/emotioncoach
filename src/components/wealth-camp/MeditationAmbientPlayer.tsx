import React, { useState, useRef, useEffect, useCallback } from "react";
import { Button } from "@/components/ui/button";
import { Slider } from "@/components/ui/slider";
import { CloudRain, Waves, Wind, Flame, TreePine, Droplets, VolumeX, Sparkles, Loader2 } from "lucide-react";
import { cn } from "@/lib/utils";
import { supabase } from "@/integrations/supabase/client";
import { useToast } from "@/hooks/use-toast";

type SoundType = 'rain' | 'ocean' | 'wind' | 'fire' | 'forest' | 'stream' | null;

interface MeditationAmbientPlayerProps {
  isPlaying: boolean;
  className?: string;
  enableHighQuality?: boolean;
}

const MeditationAmbientPlayer: React.FC<MeditationAmbientPlayerProps> = ({ 
  isPlaying,
  className,
  enableHighQuality = false,
}) => {
  const [currentSound, setCurrentSound] = useState<SoundType>(null);
  const [volume, setVolume] = useState(0.3);
  const [useHighQuality, setUseHighQuality] = useState(enableHighQuality);
  const [isLoadingHQ, setIsLoadingHQ] = useState(false);
  const { toast } = useToast();
  
  // Web Audio API refs (for synthetic sounds)
  const audioContextRef = useRef<AudioContext | null>(null);
  const noiseNodeRef = useRef<AudioBufferSourceNode | null>(null);
  const gainNodeRef = useRef<GainNode | null>(null);
  const filterNodeRef = useRef<BiquadFilterNode | null>(null);
  const lfoNodeRef = useRef<OscillatorNode | null>(null);
  const lfoGainRef = useRef<GainNode | null>(null);
  
  // HTML Audio ref (for high-quality audio)
  const hqAudioRef = useRef<HTMLAudioElement | null>(null);

  // åˆ›å»ºç™½å™ªéŸ³åŸºç¡€
  const createNoiseBuffer = useCallback((audioContext: AudioContext) => {
    const bufferSize = audioContext.sampleRate * 4; // 4ç§’å¾ªç¯
    const buffer = audioContext.createBuffer(2, bufferSize, audioContext.sampleRate);
    
    for (let channel = 0; channel < 2; channel++) {
      const data = buffer.getChannelData(channel);
      for (let i = 0; i < bufferSize; i++) {
        // æ·»åŠ è½»å¾®çš„ä½é¢‘è°ƒåˆ¶ä½¿å£°éŸ³æ›´è‡ªç„¶
        const modulation = Math.sin(i / audioContext.sampleRate * 0.5) * 0.1;
        data[i] = (Math.random() * 2 - 1) * (1 + modulation);
      }
    }
    
    return buffer;
  }, []);

  // æ ¹æ®å£°éŸ³ç±»å‹é…ç½®æ»¤æ³¢å™¨
  const configureSoundType = useCallback((soundType: SoundType, audioContext: AudioContext) => {
    if (!filterNodeRef.current) return;
    
    // æ¸…ç†ä¹‹å‰çš„LFO
    if (lfoNodeRef.current) {
      lfoNodeRef.current.stop();
      lfoNodeRef.current.disconnect();
      lfoNodeRef.current = null;
    }
    if (lfoGainRef.current) {
      lfoGainRef.current.disconnect();
      lfoGainRef.current = null;
    }
    
    switch (soundType) {
      case 'rain':
        filterNodeRef.current.type = 'bandpass';
        filterNodeRef.current.frequency.value = 1200;
        filterNodeRef.current.Q.value = 0.3;
        break;
      case 'ocean':
        // æµ·æµªå£°ï¼šä½é€šæ»¤æ³¢ + LFOè°ƒåˆ¶æ¨¡æ‹Ÿæµ·æµªèµ·ä¼
        filterNodeRef.current.type = 'lowpass';
        filterNodeRef.current.frequency.value = 500;
        filterNodeRef.current.Q.value = 1.5;
        
        // æ·»åŠ LFOæ¨¡æ‹Ÿæµ·æµªèµ·ä¼
        const lfo = audioContext.createOscillator();
        const lfoGain = audioContext.createGain();
        lfo.frequency.value = 0.1; // æ¯10ç§’ä¸€ä¸ªæ³¢æµªå‘¨æœŸ
        lfoGain.gain.value = 200;
        lfo.connect(lfoGain);
        lfoGain.connect(filterNodeRef.current.frequency);
        lfo.start();
        lfoNodeRef.current = lfo;
        lfoGainRef.current = lfoGain;
        break;
      case 'wind':
        filterNodeRef.current.type = 'bandpass';
        filterNodeRef.current.frequency.value = 400;
        filterNodeRef.current.Q.value = 0.2;
        break;
      case 'fire':
        // ç¯ç«å£°ï¼šä¸­ä½é¢‘ + è½»å¾®è°ƒåˆ¶
        filterNodeRef.current.type = 'bandpass';
        filterNodeRef.current.frequency.value = 300;
        filterNodeRef.current.Q.value = 0.8;
        break;
      case 'forest':
        // æ£®æ—å£°ï¼šä¸­é«˜é¢‘ï¼Œæ¨¡æ‹Ÿé¸Ÿé¸£å’Œæ ‘å¶æ²™æ²™å£°
        filterNodeRef.current.type = 'highpass';
        filterNodeRef.current.frequency.value = 800;
        filterNodeRef.current.Q.value = 0.3;
        break;
      case 'stream':
        // æµæ°´å£°ï¼šä¸­é¢‘ä¸ºä¸»ï¼Œå¸¦æœ‰è½»å¾®èµ·ä¼
        filterNodeRef.current.type = 'bandpass';
        filterNodeRef.current.frequency.value = 700;
        filterNodeRef.current.Q.value = 0.4;
        
        // æ·»åŠ è½»å¾®çš„é¢‘ç‡è°ƒåˆ¶æ¨¡æ‹Ÿæ°´æµå˜åŒ–
        const streamLfo = audioContext.createOscillator();
        const streamLfoGain = audioContext.createGain();
        streamLfo.frequency.value = 0.3;
        streamLfoGain.gain.value = 100;
        streamLfo.connect(streamLfoGain);
        streamLfoGain.connect(filterNodeRef.current.frequency);
        streamLfo.start();
        lfoNodeRef.current = streamLfo;
        lfoGainRef.current = streamLfoGain;
        break;
    }
  }, []);

  // åœæ­¢åˆæˆéŸ³
  const stopSyntheticSound = useCallback(() => {
    if (lfoNodeRef.current) {
      lfoNodeRef.current.stop();
      lfoNodeRef.current.disconnect();
      lfoNodeRef.current = null;
    }
    if (lfoGainRef.current) {
      lfoGainRef.current.disconnect();
      lfoGainRef.current = null;
    }
    if (noiseNodeRef.current) {
      noiseNodeRef.current.stop();
      noiseNodeRef.current.disconnect();
      noiseNodeRef.current = null;
    }
    if (audioContextRef.current) {
      audioContextRef.current.close();
      audioContextRef.current = null;
    }
  }, []);

  // åœæ­¢é«˜è´¨é‡éŸ³é¢‘
  const stopHQSound = useCallback(() => {
    if (hqAudioRef.current) {
      hqAudioRef.current.pause();
      hqAudioRef.current.src = '';
      hqAudioRef.current = null;
    }
  }, []);

  // åœæ­¢æ‰€æœ‰å£°éŸ³
  const stopSound = useCallback(() => {
    stopSyntheticSound();
    stopHQSound();
    setCurrentSound(null);
  }, [stopSyntheticSound, stopHQSound]);

  // æ’­æ”¾é«˜è´¨é‡éŸ³é¢‘
  const startHQSound = useCallback(async (soundType: SoundType) => {
    if (!soundType) return;
    
    setIsLoadingHQ(true);
    
    try {
      const { data, error } = await supabase.functions.invoke('elevenlabs-sfx', {
        body: { soundType }
      });
      
      if (error) throw error;
      
      if (data?.audioUrl) {
        const audio = new Audio(data.audioUrl);
        audio.loop = true;
        audio.volume = volume;
        hqAudioRef.current = audio;
        
        await audio.play();
        setCurrentSound(soundType);
        
        if (data.cached) {
          console.log('Using cached high-quality audio');
        } else {
          toast({
            title: "é«˜è´¨é‡éŸ³æ•ˆå·²ç”Ÿæˆ",
            description: "å·²ç¼“å­˜ï¼Œä¸‹æ¬¡å°†ç›´æ¥åŠ è½½",
          });
        }
      }
    } catch (error) {
      console.error('Failed to load HQ audio:', error);
      toast({
        variant: "destructive",
        title: "åŠ è½½å¤±è´¥",
        description: "æ— æ³•åŠ è½½é«˜è´¨é‡éŸ³æ•ˆï¼Œå°†ä½¿ç”¨åˆæˆéŸ³æ•ˆ",
      });
      // å›é€€åˆ°åˆæˆéŸ³æ•ˆ
      startSyntheticSound(soundType);
    } finally {
      setIsLoadingHQ(false);
    }
  }, [volume, toast]);

  // æ’­æ”¾åˆæˆéŸ³æ•ˆ
  const startSyntheticSound = useCallback((soundType: SoundType) => {
    stopSound();
    
    if (!soundType) return;
    
    const audioContext = new (window.AudioContext || (window as any).webkitAudioContext)();
    audioContextRef.current = audioContext;
    
    const gainNode = audioContext.createGain();
    gainNode.gain.value = volume;
    gainNodeRef.current = gainNode;
    
    const filterNode = audioContext.createBiquadFilter();
    filterNodeRef.current = filterNode;
    configureSoundType(soundType, audioContext);
    
    const noiseBuffer = createNoiseBuffer(audioContext);
    const noiseNode = audioContext.createBufferSource();
    noiseNode.buffer = noiseBuffer;
    noiseNode.loop = true;
    noiseNodeRef.current = noiseNode;
    
    noiseNode.connect(filterNode);
    filterNode.connect(gainNode);
    gainNode.connect(audioContext.destination);
    
    noiseNode.start();
    setCurrentSound(soundType);
  }, [volume, configureSoundType, createNoiseBuffer, stopSound]);

  // å¼€å§‹æ’­æ”¾
  const startSound = useCallback((soundType: SoundType) => {
    stopSound();
    
    if (!soundType) return;
    
    if (useHighQuality) {
      startHQSound(soundType);
    } else {
      startSyntheticSound(soundType);
    }
  }, [useHighQuality, startHQSound, startSyntheticSound, stopSound]);

  // æš‚åœ/æ¢å¤
  const pauseSound = useCallback(() => {
    if (audioContextRef.current && audioContextRef.current.state === 'running') {
      audioContextRef.current.suspend();
    }
    if (hqAudioRef.current && !hqAudioRef.current.paused) {
      hqAudioRef.current.pause();
    }
  }, []);

  const resumeSound = useCallback(() => {
    if (audioContextRef.current && audioContextRef.current.state === 'suspended') {
      audioContextRef.current.resume();
    }
    if (hqAudioRef.current && hqAudioRef.current.paused && currentSound) {
      hqAudioRef.current.play();
    }
  }, [currentSound]);

  // åˆ‡æ¢å£°éŸ³
  const toggleSound = useCallback((soundType: SoundType) => {
    if (currentSound === soundType) {
      stopSound();
    } else {
      startSound(soundType);
    }
  }, [currentSound, startSound, stopSound]);

  // åˆ‡æ¢é«˜è´¨é‡æ¨¡å¼
  const toggleHighQuality = useCallback(() => {
    const newValue = !useHighQuality;
    setUseHighQuality(newValue);
    
    // å¦‚æœå½“å‰æ­£åœ¨æ’­æ”¾ï¼Œé‡æ–°åŠ è½½éŸ³æ•ˆ
    if (currentSound) {
      stopSound();
      if (newValue) {
        startHQSound(currentSound);
      } else {
        startSyntheticSound(currentSound);
      }
    }
  }, [useHighQuality, currentSound, stopSound, startHQSound, startSyntheticSound]);

  // éŸ³é‡å˜åŒ–
  useEffect(() => {
    if (gainNodeRef.current) {
      gainNodeRef.current.gain.value = volume;
    }
    if (hqAudioRef.current) {
      hqAudioRef.current.volume = volume;
    }
  }, [volume]);

  // ä¸ä¸»éŸ³é¢‘åŒæ­¥æ’­æ”¾çŠ¶æ€
  useEffect(() => {
    if (currentSound) {
      if (isPlaying) {
        resumeSound();
      } else {
        pauseSound();
      }
    }
  }, [isPlaying, currentSound, pauseSound, resumeSound]);

  // ç»„ä»¶å¸è½½æ—¶æ¸…ç†
  useEffect(() => {
    return () => {
      stopSound();
    };
  }, [stopSound]);

  const sounds = [
    { type: 'rain' as SoundType, icon: CloudRain, label: 'é›¨å£°' },
    { type: 'stream' as SoundType, icon: Droplets, label: 'æµæ°´' },
    { type: 'ocean' as SoundType, icon: Waves, label: 'æµ·æµª' },
    { type: 'forest' as SoundType, icon: TreePine, label: 'æ£®æ—' },
    { type: 'fire' as SoundType, icon: Flame, label: 'ç¯ç«' },
    { type: 'wind' as SoundType, icon: Wind, label: 'é£å£°' },
  ];

  return (
    <div className={className}>
      <div className="flex items-center justify-between mb-2">
        <div className="flex items-center gap-2">
          <span className="text-sm text-muted-foreground">ğŸµ èƒŒæ™¯éŸ³æ•ˆ</span>
          <Button
            variant="ghost"
            size="sm"
            className={cn(
              "h-6 px-2 text-xs rounded-full transition-all",
              useHighQuality 
                ? "bg-amber-500/20 text-amber-600 ring-1 ring-amber-500/30" 
                : "text-muted-foreground hover:text-amber-600"
            )}
            onClick={toggleHighQuality}
            disabled={isLoadingHQ}
          >
            {isLoadingHQ ? (
              <Loader2 className="w-3 h-3 mr-1 animate-spin" />
            ) : (
              <Sparkles className="w-3 h-3 mr-1" />
            )}
            é«˜è´¨é‡
          </Button>
        </div>
        {currentSound && (
          <Button
            variant="ghost"
            size="sm"
            className="h-6 px-2 text-xs text-muted-foreground hover:text-foreground"
            onClick={stopSound}
          >
            <VolumeX className="w-3 h-3 mr-1" />
            å…³é—­
          </Button>
        )}
      </div>
      
      <div className="flex items-center gap-1 flex-wrap">
        {sounds.map(({ type, icon: Icon, label }) => (
          <Button
            key={type}
            variant="ghost"
            size="sm"
            disabled={isLoadingHQ}
            className={cn(
              "h-8 px-2 rounded-full transition-all",
              currentSound === type 
                ? 'bg-amber-500/20 text-amber-600 hover:bg-amber-500/30 ring-1 ring-amber-500/30' 
                : 'text-muted-foreground hover:text-amber-600 hover:bg-amber-500/10'
            )}
            onClick={() => toggleSound(type)}
            title={label}
          >
            <Icon className="w-4 h-4 mr-1" />
            <span className="text-xs">{label}</span>
          </Button>
        ))}
      </div>
      
      {currentSound && (
        <div className="flex items-center gap-2 mt-3">
          <span className="text-xs text-muted-foreground whitespace-nowrap">éŸ³é‡</span>
          <Slider
            value={[volume * 100]}
            onValueChange={([v]) => setVolume(v / 100)}
            max={100}
            step={1}
            className="flex-1"
          />
          <span className="text-xs text-muted-foreground w-8">{Math.round(volume * 100)}%</span>
        </div>
      )}
    </div>
  );
};

export default MeditationAmbientPlayer;
