/**
 * å°ç¨‹åºè¯­éŸ³ä¸­ç»§ Edge Function
 * 
 * åŠŸèƒ½ï¼šä½œä¸º WebSocket ä»£ç†ï¼Œåœ¨å°ç¨‹åºå’Œ OpenAI Realtime API ä¹‹é—´è½¬å‘éŸ³é¢‘æ•°æ®
 * 
 * æ¶æ„ï¼š
 * å°ç¨‹åº <--WebSocket--> æ­¤ Edge Function <--WebSocket--> OpenAI Realtime API
 */

import { corsHeaders } from '../_shared/cors.ts';

const OPENAI_API_KEY = Deno.env.get('OPENAI_API_KEY');
const OPENAI_REALTIME_URL = 'wss://api.openai.com/v1/realtime?model=gpt-4o-mini-realtime-preview-2024-12-17';

// éŸ³é¢‘æ ¼å¼é…ç½®
const AUDIO_CONFIG = {
  format: 'pcm16',
  sampleRate: 24000,
};

interface ClientMessage {
  type: string;
  audio?: string;
  text?: string;
}

Deno.serve(async (req) => {
  // å¤„ç† CORS é¢„æ£€è¯·æ±‚
  if (req.method === 'OPTIONS') {
    return new Response(null, { headers: corsHeaders });
  }

  // æ£€æŸ¥æ˜¯å¦ä¸º WebSocket å‡çº§è¯·æ±‚
  const upgrade = req.headers.get('upgrade') || '';
  if (upgrade.toLowerCase() !== 'websocket') {
    return new Response(
      JSON.stringify({ error: 'Expected WebSocket upgrade' }),
      { 
        status: 426, 
        headers: { ...corsHeaders, 'Content-Type': 'application/json' } 
      }
    );
  }

  // è§£æ URL å‚æ•°
  const url = new URL(req.url);
  const token = url.searchParams.get('token');
  const mode = url.searchParams.get('mode') || 'vibrant_life';

  if (!token) {
    return new Response(
      JSON.stringify({ error: 'Missing token parameter' }),
      { 
        status: 400, 
        headers: { ...corsHeaders, 'Content-Type': 'application/json' } 
      }
    );
  }

  if (!OPENAI_API_KEY) {
    return new Response(
      JSON.stringify({ error: 'OpenAI API key not configured' }),
      { 
        status: 500, 
        headers: { ...corsHeaders, 'Content-Type': 'application/json' } 
      }
    );
  }

  // å‡çº§åˆ° WebSocket
  const { socket: clientSocket, response } = Deno.upgradeWebSocket(req);

  let openaiSocket: WebSocket | null = null;
  let isConnected = false;
  let healthCheckInterval: ReturnType<typeof setInterval> | null = null;

  // ğŸ”§ å®šæœŸæ£€æŸ¥ OpenAI è¿æ¥å¥åº·çŠ¶æ€
  const startHealthCheck = () => {
    healthCheckInterval = setInterval(() => {
      if (openaiSocket?.readyState !== WebSocket.OPEN) {
        console.log('[Relay] OpenAI connection lost, closing client');
        if (clientSocket.readyState === WebSocket.OPEN) {
          clientSocket.close(1000, 'OpenAI connection lost');
        }
        if (healthCheckInterval) {
          clearInterval(healthCheckInterval);
        }
      }
    }, 5000);
  };

  const stopHealthCheck = () => {
    if (healthCheckInterval) {
      clearInterval(healthCheckInterval);
      healthCheckInterval = null;
    }
  };

  // å¤„ç†å®¢æˆ·ç«¯è¿æ¥
  clientSocket.onopen = async () => {
    console.log('[Relay] Client connected');

    try {
      // è¿æ¥åˆ° OpenAI Realtime API
      openaiSocket = new WebSocket(OPENAI_REALTIME_URL, [
        'realtime',
        `openai-insecure-api-key.${OPENAI_API_KEY}`,
        'openai-beta.realtime-v1',
      ]);

      openaiSocket.onopen = () => {
        console.log('[Relay] Connected to OpenAI');
        isConnected = true;
        startHealthCheck(); // ğŸ”§ å¯åŠ¨å¥åº·æ£€æŸ¥

        // å‘é€ä¼šè¯é…ç½®
        const sessionConfig = {
          type: 'session.update',
          session: {
            modalities: ['text', 'audio'],
            instructions: getSystemPrompt(mode),
            voice: mode === 'teen' ? 'shimmer' : 'echo', // ç»Ÿä¸€è¯­éŸ³ï¼šé’å°‘å¹´ç”¨ shimmerï¼Œå…¶ä»–ç”¨ echo
            input_audio_format: AUDIO_CONFIG.format,
            output_audio_format: AUDIO_CONFIG.format,
            // ç”¨æˆ·ä½“éªŒä¼˜å…ˆï¼šä¸ç¡¬æ€§é™åˆ¶ tokenï¼Œé€šè¿‡ Prompt è½¯æ§åˆ¶å›å¤é•¿åº¦
            // é¿å… AI è¯´è¯è¯´åˆ°ä¸€åŠè¢«æˆªæ–­
            max_response_output_tokens: "inf",
            input_audio_transcription: {
              model: 'whisper-1',
            },
            turn_detection: {
              type: 'server_vad',
              threshold: 0.6, // æé«˜é˜ˆå€¼ï¼Œå‡å°‘èƒŒæ™¯å™ªéŸ³æ•æ‰
              prefix_padding_ms: 200, // å‡å°‘å‰ç¼€å¡«å……ï¼Œä¸ WebRTC ä¸€è‡´
              silence_duration_ms: 1200, // å¢åŠ é™é»˜æ—¶é•¿ï¼Œä¸ WebRTC ä¸€è‡´ï¼Œå‡å°‘è¯­éŸ³è¢«æˆªæ–­
            },
          },
        };

        openaiSocket!.send(JSON.stringify(sessionConfig));
      };

      openaiSocket.onmessage = (event) => {
        handleOpenAIMessage(event.data, clientSocket);
      };

      openaiSocket.onerror = (error) => {
        console.error('[Relay] OpenAI WebSocket error:', error);
        sendErrorToClient(clientSocket, 'OpenAI connection error');
      };

      openaiSocket.onclose = (event) => {
        console.log('[Relay] OpenAI disconnected:', event.code, event.reason);
        isConnected = false;
        stopHealthCheck(); // ğŸ”§ åœæ­¢å¥åº·æ£€æŸ¥
        if (clientSocket.readyState === WebSocket.OPEN) {
          clientSocket.close(1000, 'OpenAI disconnected');
        }
      };
    } catch (error) {
      console.error('[Relay] Failed to connect to OpenAI:', error);
      sendErrorToClient(clientSocket, 'Failed to connect to AI service');
    }
  };

  // å¤„ç†å®¢æˆ·ç«¯æ¶ˆæ¯
  clientSocket.onmessage = (event) => {
    if (!isConnected || !openaiSocket) {
      console.warn('[Relay] Received message but not connected to OpenAI');
      return;
    }

    try {
      const message: ClientMessage = JSON.parse(event.data);

      switch (message.type) {
        case 'audio_input':
          // è½¬å‘éŸ³é¢‘æ•°æ®åˆ° OpenAI
          if (message.audio) {
            openaiSocket.send(JSON.stringify({
              type: 'input_audio_buffer.append',
              audio: message.audio,
            }));
          }
          break;

        case 'text_input':
          // è½¬å‘æ–‡æœ¬æ¶ˆæ¯åˆ° OpenAI
          if (message.text) {
            openaiSocket.send(JSON.stringify({
              type: 'conversation.item.create',
              item: {
                type: 'message',
                role: 'user',
                content: [{ type: 'input_text', text: message.text }],
              },
            }));
            openaiSocket.send(JSON.stringify({ type: 'response.create' }));
          }
          break;

        case 'ping':
          // å¿ƒè·³å“åº”
          clientSocket.send(JSON.stringify({ type: 'pong' }));
          break;

        case 'commit_audio':
          // æäº¤éŸ³é¢‘ç¼“å†²åŒº
          openaiSocket.send(JSON.stringify({ type: 'input_audio_buffer.commit' }));
          break;

        default:
          // ç›´æ¥è½¬å‘å…¶ä»–æ¶ˆæ¯
          openaiSocket.send(event.data);
      }
    } catch (error) {
      console.error('[Relay] Failed to process client message:', error);
    }
  };

  // å¤„ç†å®¢æˆ·ç«¯æ–­å¼€
  clientSocket.onclose = (event) => {
    console.log('[Relay] Client disconnected:', event.code, event.reason);
    stopHealthCheck(); // ğŸ”§ åœæ­¢å¥åº·æ£€æŸ¥
    if (openaiSocket) {
      openaiSocket.close();
      openaiSocket = null;
    }
  };

  // å¤„ç†å®¢æˆ·ç«¯é”™è¯¯
  clientSocket.onerror = (error) => {
    console.error('[Relay] Client WebSocket error:', error);
  };

  return response;
});

/**
 * å¤„ç†æ¥è‡ª OpenAI çš„æ¶ˆæ¯
 */
function handleOpenAIMessage(data: string, clientSocket: WebSocket) {
  if (clientSocket.readyState !== WebSocket.OPEN) {
    return;
  }

  try {
    const message = JSON.parse(data);

    switch (message.type) {
      case 'response.audio.delta':
        // è½¬å‘éŸ³é¢‘å¢é‡
        if (message.delta) {
          clientSocket.send(JSON.stringify({
            type: 'audio_output',
            audio: message.delta,
          }));
        }
        break;

      case 'response.audio_transcript.delta':
        // è½¬å‘ AI å“åº”è½¬å½•ï¼ˆéƒ¨åˆ†ï¼‰
        if (message.delta) {
          clientSocket.send(JSON.stringify({
            type: 'transcript',
            text: message.delta,
            isFinal: false,
            role: 'assistant',
          }));
        }
        break;

      case 'response.audio_transcript.done':
        // AI å“åº”è½¬å½•å®Œæˆ
        if (message.transcript) {
          clientSocket.send(JSON.stringify({
            type: 'transcript',
            text: message.transcript,
            isFinal: true,
            role: 'assistant',
          }));
        }
        break;

      case 'conversation.item.input_audio_transcription.completed':
        // ç”¨æˆ·è¯­éŸ³è½¬å½•å®Œæˆ
        if (message.transcript) {
          clientSocket.send(JSON.stringify({
            type: 'transcript',
            text: message.transcript,
            isFinal: true,
            role: 'user',
          }));
        }
        break;

      case 'response.done':
        // å“åº”å®Œæˆï¼ŒåŒ…å« usage ä¿¡æ¯
        if (message.response?.usage) {
          clientSocket.send(JSON.stringify({
            type: 'usage',
            usage: {
              input_tokens: message.response.usage.input_tokens || 0,
              output_tokens: message.response.usage.output_tokens || 0,
            },
          }));
        }
        // è½¬å‘å®Œæˆäº‹ä»¶
        clientSocket.send(JSON.stringify({
          type: 'response.done',
          response: message.response,
        }));
        break;

      case 'error':
        // è½¬å‘é”™è¯¯
        console.error('[Relay] OpenAI error:', message.error);
        clientSocket.send(JSON.stringify({
          type: 'error',
          error: message.error?.message || 'Unknown error',
        }));
        break;

      case 'session.created':
      case 'session.updated':
        // ä¼šè¯çŠ¶æ€äº‹ä»¶
        clientSocket.send(JSON.stringify({
          type: message.type,
          session: message.session,
        }));
        break;

      case 'input_audio_buffer.speech_started':
        // ç”¨æˆ·å¼€å§‹è¯´è¯
        clientSocket.send(JSON.stringify({
          type: 'speech_started',
        }));
        break;

      case 'input_audio_buffer.speech_stopped':
        // ç”¨æˆ·åœæ­¢è¯´è¯
        clientSocket.send(JSON.stringify({
          type: 'speech_stopped',
        }));
        break;

      default:
        // å…¶ä»–äº‹ä»¶å¯æŒ‰éœ€è½¬å‘
        // console.log('[Relay] Unhandled OpenAI event:', message.type);
        break;
    }
  } catch (error) {
    console.error('[Relay] Failed to parse OpenAI message:', error);
  }
}

/**
 * å‘é€é”™è¯¯æ¶ˆæ¯ç»™å®¢æˆ·ç«¯
 */
function sendErrorToClient(socket: WebSocket, message: string) {
  if (socket.readyState === WebSocket.OPEN) {
    socket.send(JSON.stringify({
      type: 'error',
      error: message,
    }));
  }
}

/**
 * æ ¹æ®æ¨¡å¼è·å–ç³»ç»Ÿæç¤ºè¯
 */
function getSystemPrompt(mode: string): string {
  // é€šç”¨å¯¹è¯èŠ‚å¥è§„åˆ™ - æ‰€æœ‰æ¨¡å¼éƒ½éµå¾ª
  const rhythmRules = `

ã€å¯¹è¯èŠ‚å¥è§„åˆ™ - éå¸¸é‡è¦ã€‘
- æ¯æ¬¡å›å¤2-4å¥ï¼Œä¸è¦é•¿ç¯‡å¤§è®º
- å¤æ‚å†…å®¹åˆ†å¤šæ¬¡è¯´ï¼š"æˆ‘å…ˆè¯´ä¸€ç‚¹..."
- è‡ªç„¶åœé¡¿ï¼Œç•™ç©ºé—´ç»™ç”¨æˆ·
- ç¡®ä¿æ¯å¥è¯è¯´å®Œæ•´`;

  const prompts: Record<string, string> = {
    vibrant_life: `ä½ æ˜¯æœ‰åŠ²AIç”Ÿæ´»æ•™ç»ƒï¼Œä¸€ä½æ¸©æš–ã€æ™ºæ…§ã€å……æ»¡æ´»åŠ›çš„é™ªä¼´è€…ã€‚ä½ çš„ä½¿å‘½æ˜¯å¸®åŠ©ç”¨æˆ·æ‰¾åˆ°ç”Ÿæ´»çš„çƒ­æƒ…å’Œæ–¹å‘ã€‚

æ ¸å¿ƒåŸåˆ™ï¼š
1. å€¾å¬ç†è§£ï¼šçœŸæ­£å¬æ‡‚ç”¨æˆ·çš„å›°æƒ‘å’Œéœ€æ±‚
2. æ¸©æš–æ”¯æŒï¼šç»™äºˆæ— æ¡ä»¶çš„æ¥çº³å’Œé¼“åŠ±
3. æ™ºæ…§å¼•å¯¼ï¼šç”¨é—®é¢˜å¼•å‘æ€è€ƒï¼Œè€Œéç›´æ¥ç»™ç­”æ¡ˆ
4. è¡ŒåŠ¨å¯¼å‘ï¼šå¸®åŠ©ç”¨æˆ·åˆ¶å®šå¯æ‰§è¡Œçš„å°æ­¥éª¤

å¯¹è¯é£æ ¼ï¼š
- è¯­æ°”æ¸©æš–è‡ªç„¶ï¼Œåƒæœ‹å‹èŠå¤©
- é€‚æ—¶ä½¿ç”¨emojiå¢åŠ äº²å’ŒåŠ›
- å¤šç”¨å¼€æ”¾æ€§é—®é¢˜å¼•å¯¼æ€è€ƒ${rhythmRules}`,

    emotion: `ä½ æ˜¯æœ‰åŠ²AIæƒ…ç»ªæ•™ç»ƒï¼Œä¸“æ³¨äºå¸®åŠ©ç”¨æˆ·ç†è§£å’Œè½¬åŒ–æƒ…ç»ªã€‚ä½ è¿ç”¨æƒ…ç»ªå››éƒ¨æ›²ï¼šè§‰å¯Ÿã€ç†è§£ã€ååº”ã€è½¬åŒ–ã€‚

æ ¸å¿ƒåŸåˆ™ï¼š
1. è§‰å¯Ÿï¼šå¸®åŠ©ç”¨æˆ·æ„Ÿå—å¹¶å‘½åæƒ…ç»ª
2. ç†è§£ï¼šæ¢ç´¢æƒ…ç»ªèƒŒåçš„éœ€æ±‚å’Œä»·å€¼
3. ååº”ï¼šè§‰å¯Ÿæƒ…ç»ªé©±åŠ¨çš„ååº”æ¨¡å¼
4. è½¬åŒ–ï¼šå¼•å¯¼æ¸©æŸ”å›åº”ï¼Œæ‰¾åˆ°æ–°å¯èƒ½

å¯¹è¯é£æ ¼ï¼š
- æ¸©æŸ”æ¥çº³ï¼Œä¸è¯„åˆ¤ä»»ä½•æƒ…ç»ª
- ç”¨åæ˜ å¼å€¾å¬ç¡®è®¤æ„Ÿå—
- å¼•å¯¼è€Œéè¯´æ•™${rhythmRules}`,

    parent: `ä½ æ˜¯æœ‰åŠ²AIäº²å­æ•™ç»ƒï¼Œå¸®åŠ©å®¶é•¿ç†è§£å­©å­ã€æ”¹å–„äº²å­å…³ç³»ã€‚

æ ¸å¿ƒåŸåˆ™ï¼š
1. ç†è§£å­©å­çš„å†…å¿ƒä¸–ç•Œå’Œå‘å±•éœ€æ±‚
2. å¸®åŠ©å®¶é•¿çœ‹åˆ°å­©å­è¡Œä¸ºèƒŒåçš„éœ€æ±‚
3. æä¾›å…·ä½“å¯è¡Œçš„æ²Ÿé€šæŠ€å·§
4. æ”¯æŒå®¶é•¿çš„æƒ…ç»ªï¼Œä¸è¯„åˆ¤

å¯¹è¯é£æ ¼ï¼š
- åŒç†å®¶é•¿çš„è¾›è‹¦å’Œå›°æƒ‘
- ç”¨æ•…äº‹å’Œä¾‹å­è¯´æ˜
- æä¾›å…·ä½“çš„è¯æœ¯å»ºè®®
- é¼“åŠ±å°æ­¥å°è¯•${rhythmRules}`,

    teen: `ä½ æ˜¯æœ‰åŠ²AIé’å°‘å¹´æ•™ç»ƒï¼Œä¸“ä¸ºé’å°‘å¹´è®¾è®¡çš„æ¸©æš–ä¼™ä¼´ã€‚

æ ¸å¿ƒåŸåˆ™ï¼š
1. ç†è§£é’å°‘å¹´çš„ç‹¬ç‰¹è§†è§’å’Œå‹åŠ›
2. ä¸è¯´æ•™ï¼Œä»¥å¹³ç­‰çš„å§¿æ€äº¤æµ
3. å°Šé‡éšç§ï¼Œå»ºç«‹ä¿¡ä»»
4. å¸®åŠ©è¡¨è¾¾çœŸå®æ„Ÿå—

å¯¹è¯é£æ ¼ï¼š
- è¯­æ°”è½»æ¾è‡ªç„¶ï¼Œåƒæœ‹å‹èŠå¤©
- ä¸è¯„åˆ¤ï¼Œç»™äºˆæ— æ¡ä»¶æ¥çº³
- æä¾›æƒ…ç»ªæ”¯æŒè€Œéè§£å†³æ–¹æ¡ˆ
- é¼“åŠ±è‡ªæˆ‘æ¢ç´¢å’Œç‹¬ç«‹æ€è€ƒ
- é€‚å½“ä½¿ç”¨å¹´è½»äººçš„è¡¨è¾¾æ–¹å¼${rhythmRules}`,

    general: `ä½ æ˜¯æœ‰åŠ²AIæ™ºèƒ½åŠ©æ‰‹ï¼Œä¸€ä½å‹å–„ã€ä¸“ä¸šçš„å¯¹è¯ä¼™ä¼´ã€‚

æ ¸å¿ƒåŸåˆ™ï¼š
1. è®¤çœŸå€¾å¬ï¼Œç†è§£ç”¨æˆ·éœ€æ±‚
2. æä¾›æ¸…æ™°ã€æœ‰å¸®åŠ©çš„å›åº”
3. ä¿æŒå‹å¥½å’Œä¸“ä¸šçš„æ€åº¦
4. å¿…è¦æ—¶å¼•å¯¼ç”¨æˆ·å¯»æ±‚ä¸“ä¸šå¸®åŠ©

å¯¹è¯é£æ ¼ï¼š
- è¯­æ°”è‡ªç„¶äº²åˆ‡
- é€‚æ—¶æä¾›å»ºè®®
- ä¿æŒå¼€æ”¾å’ŒåŒ…å®¹${rhythmRules}`,

    wealth: `ä½ æ˜¯æœ‰åŠ²AIè´¢å¯Œæ•™ç»ƒï¼Œå¸®åŠ©ç”¨æˆ·å‘ç°å¹¶çªç ´è´¢å¯Œå¡ç‚¹ã€‚

æ ¸å¿ƒåŸåˆ™ï¼š
1. å¸®åŠ©ç”¨æˆ·è§‰å¯Ÿè´¢å¯Œä¿¡å¿µå’Œè¡Œä¸ºæ¨¡å¼
2. æ¢ç´¢è´¢å¯Œå¡ç‚¹èƒŒåçš„æƒ…ç»ªå’Œé™åˆ¶æ€§ä¿¡å¿µ
3. å¼•å¯¼ç”¨æˆ·é‡æ–°å®šä¹‰ä¸é‡‘é’±çš„å…³ç³»
4. æ”¯æŒç”¨æˆ·é‡‡å–å°æ­¥è¡ŒåŠ¨çªç ´å¡ç‚¹

å¯¹è¯é£æ ¼ï¼š
- æ¸©å’Œä¸è¯„åˆ¤ï¼Œæ¥çº³ç”¨æˆ·çš„è´¢å¯Œç„¦è™‘
- ç”¨æé—®å¼•å¯¼è‡ªæˆ‘è§‰å¯Ÿ
- å…³æ³¨å†…åœ¨ä¿¡å¿µè€Œéå¤–åœ¨æŠ€å·§
- é¼“åŠ±ç»™äºˆå’Œæ„Ÿæ©çš„è¡ŒåŠ¨${rhythmRules}`
  };

  return prompts[mode] || prompts.vibrant_life;
}
